---
title: "ST404_Assignment_2_Findings"
output: pdf_document
fontsize: 11pt
linestretch: 1.5
---

# Findings

## Data cleaning and outliers

With respect to previous explanatory data analysis, some cleaning of the data was required. With regards to the 152 missing values of the PctEmployed16_Over, we have decided to remove this column entirely in order to maintain a larger sample size from which to construct a model. It is also strongly negatively correlated to PctUnemployed16_Over and so having both variables would not add much value. We also mutliply the infeasibly small values (those less than 0.1) of AvgHouseholdSize by 100 in order to fix them.

Several counties were identified as having very large leverage and are therefore likely to have a larger influence on variable coefficients in the model. It is not desirable to have such a small number of counties to have such a large impact on the model since we want the bulk of the counties to influence our future predictions and form our analysis of the causes of higher cancer death rates. Therefore, these counties have been removed. The counties are (....??).

### Utilising the geography variable

In order to account for different death rates found in different states within the US, we divided the US in to 4 regions and allocated each county in to one of these 4 regions. This variable could then be used to construct a model.

## Transformations

Some transformations of the predictor variables were required in order to fulfil the linear model assumptions. Transformations were kept to a minimum in order to keep the model as simple as possible. We performed the following transformations (...??)

## Initial modelling

Several variable selection methods were trialed in order to construct the best model in terms of simplicity, explanatory power and predictive power. These methods were Stepwise variable selection and LASSO regression.

After utilising these techniques, models were often showing signs of multicollinearity. This violates one of our model assumptions and means that our variable coefficients are difficult to interpret, reducing explanatory power. Therefore, some adjustments to models were required after using the variable selection techniques.

### Stepwise selection

Stepwise regression is a variable selection technique which uses the following algorithm:  
1. Start with initial model (usually full or null model).  
2. Add or remove the variables that minimises the AIC or BIC.  
3. Repeat (2) until no improvements can be made.  

When we did this we found that, despite our initial data cleaning and transformations, there were issues with collinearity. As a result we looked at which variables we believed were most important and tried to remove issues with respect to collinearity with that in mind. Each time we removed one variable from the full model and ran the stepwise regression function again and reassessed whether there were any collinearity issues. Once these we eliminated we checked the residuals vs fitted plot to see if there was any issues with heteroscedastcity or any other model assumptions were broken.

The model suggested by stepwise regression is shown below.

```{r Model Table, echo=FALSE}
name=c('incidenceRate','povertyPercent','PctUnemployed16_Over',
       'PctPublicCoverage','PctBlack','PercentMarried')
transformation=c('incidenceRate^(1.5)','None','PctUnemployed16_Over^(0.5)','None','log(PctBlack+0.1)',
                'None')
pVals=c('<2e-16','<2e-16','1.3e-8','1.1e-14','2.0e-12','<2e-16')
beta=c('0.00768','1.53','4.71','0.556','2.02','0.858')
modelTable=as.table(matrix(data=c(transformation,pVals,beta),nrow=6,ncol=3))
rownames(modelTable)=name
colnames(modelTable)=c('Transformation','p-value','Parameter estimate')
knitr::kable(modelTable, caption = "Information on the final model")
```

**Interpretation**

This model shows, for incidence rate, the value of the parameter estimate is 0.00740. Since the variable is raised to the power of 1.5, this means that if the incidence rate quadruples, then the death rate will increase by 8 times. For example, if the incidence rate changes from 100 to 400 cases per 100000 people, then the death rate will increase from 7.68 to 61.44, if all other variables are equal to 0. Another transformed variable is `PctBlack`, for this variable a parameter estimate of 2.02 means that if the percentage of black population increases then the death rate will increase. The exact amount of the death rate decrease is dependent on what your percentage increases from and to but the marginal increase in death rate decreases as the percentage of black population increases. For example an observed increase in black population from 1% to 2% will result in a larger increase in death rate than 50% to 51%. The last transformed variable is `PctUnemployed16_Over`, it has a coefficient of 4.71 and it is raised to the power of $\frac{1}{2}$. This means that if the unemployment rate quadruples  then the death rate will double. For example, if the unemployment rate goes from 5% to 20% then the death rate will go from 10.5 to 21.1, if all other variables are equal to 0.

The other variables in the model are not transformed. The percentage of people with public coverage, the percentage of people in poverty and the percentage of people married have a coefficient of 0.556, 1.53 and 0.858 respectively. This means that for every percentage increase in the amount of people with public coverage, in poverty and that are married the death rate increases by 0.556, 1.53 and 0.858 respectively, assuming all other variables stay the same.

All of the variables also have low p-values, they are all significant at the 0.1% significance level which means all of their inclusions in the model are justified. Finally, the F-statistic for the model has a value of 37040 on 6 and 3035 degrees of freedom. This is a high value for the F-statistic and it has an extremely low p-value, less than 2.2e-16, this confirms that the model is a much better fit for the data than a model with just an intercept.


### LASSO regression

#This code shoudl be sufficent to recreate the model I made on it's own

```{r, eval = FALSE}

cancer3 <- cancerRaw
cancer3$AvgHouseholdSize[cancer3$AvgHouseholdSize <= 0.1] <- cancer3$AvgHouseholdSize[cancer3$AvgHouseholdSize <= 0.1]*100
cancer3 <- cancer3[-c(2682, 282, 166, 2727, 2714, 1490),]

cancer3 = separate(cancer3,"Geography",c("County","State"),sep = ", ")
cancer3 <- cancer3 %>%
  mutate(Region = case_when(
    State %in% c("New Hampshire","New Jersey","New York","Maine","Massachusetts","Vermont","Connecticut","Pennsylvania","Rhode Island") ~ "Northeast",
    State %in% c("Wisconsin","Nebraska","Michigan","Minnesota","North Dakota","Missouri","Kansas","Ohio","Indiana","Iowa","Illinois","South Dakota") ~ "Midwest",
    State %in% c("West Virginia","Virginia","North Carolina","Alabama","Arkansas","Tennessee","Texas","Louisiana","Maryland","Mississippi","Kentucky","Delaware","District of Columbia","Florida","Oklahoma","South Carolina","Georgia") ~ "South",
    State %in% c("Washington","Nevada","New Mexico","California","Montana","Utah","Colorado","Wyoming","Oregon","Hawaii","Idaho","Alaska","Arizona") ~ "West"
  ))
cancer3$Region <-  factor(cancer3$Region)

cancerLASSO <- cancer3[,-c(1,2,5,11,19)]

cancerLASSO$incidenceRate <- boxcox(cancerLASSO$incidenceRate, p = 1.5)
cancerLASSO$PctBlack <- log(cancerLASSO$PctBlack + 0.1 )
cancerLASSO$PctUnemployed16_Over <- boxcox(cancerLASSO$PctUnemployed16_Over, p = 0.5)
cancerLASSO$medIncome <- log(cancerLASSO$medIncome)


cancerLASSO <- model.matrix(~., data = cancerLASSO)

LASSO <- glmnet(cancerLASSO, cancer3$deathRate, alpha = 1) 
cvLASSO <- cv.glmnet(cancerLASSO, cancer3$deathRate, alpha = 1)
LASSOmodel <- glmnet(cancerLASSO, cancer3$deathRate, alpha = 1, lambda = cvLASSO$lambda.1se)


LASSOpredicted <- predict(LASSOmodel, newx = cancerLASSO)
LASSOresiduals <- cancer3$deathRate - LASSOpredicted

LASSO_Rsquared <- 1 - (sum(LASSOresiduals^2)/sum((cancer3$deathRate - mean(cancer3$deathRate))^2))

```



## The final model

Our final model can be summarised in the table below

```{r,eval=FALSE,echo=FALSE}
DF <- data.frame(row.names=c(),coefficient=c(),p-value=c())
DF
```


### Analysis of the model

Predictive power - 

Explanatory power - 

Simplicity - 

Model plots - 

```{r,eval=FALSE,echo=FALSE}
par(mfrow=c(2,2))
plot(model)
```


### Areas that do not conform to the general pattern

We look for outliers within our model, as well as seeing if the counties we removed for having high leverage initially conform to our model and therefore to the general pattern. 

### Limitations


